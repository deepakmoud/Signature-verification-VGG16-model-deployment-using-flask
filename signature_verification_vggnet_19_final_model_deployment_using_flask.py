# -*- coding: utf-8 -*-
"""signature verification vggnet 19 final Model deployment  using Flask.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ux0IdyeERVlpeEvfGzoM0w2US2ZHWfI-
"""

# Importing the Keras libraries and packages
from keras.layers import Input, Flatten, Dense
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.preprocessing import image
import numpy as np
import pandas as pd
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Input, Flatten, Dense
from keras.callbacks import Callback, ModelCheckpoint
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg19 import VGG19
import warnings 
warnings.filterwarnings('ignore')
img_width, img_height = 128, 128

#Load the pretrained Network
vgg19_model = VGG19(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_height,img_width,3), pooling=None, classes=1000)
print("pretrained Network is loaded")

pip install -U keras

# Freeze the layers
for layer in vgg19_model.layers:
    layer.trainable = False
print("Pretrained layers are freezed")

model = Sequential()
model.add(vgg19_model)
#add fully connected layer:
input_layer=model.add(Flatten())
hidden_layer=model.add(Dense(128, activation='relu', name='hidden_layer'))
classification_layer=model.add(Dense(64, activation='relu', name='classification_layer'))
output_layer=model.add(Dense(1, activation='sigmoid', name='output_layer')) 
print("All layers top of pretrained layers are developed")

train_data_dir ='/content/drive/My Drive/Dataset1/training_set'
val_data_dir ='/content/drive/My Drive/Dataset1/testing_set'
nb_epochs = 35
print("Input parameters are assigned")

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print("Model is Complied")

from google.colab import drive
drive.mount('/content/drive')

train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), 
                                                    batch_size=32,shuffle=False, class_mode='binary')
validation_generator = test_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), 
                                                    batch_size=32,shuffle=False,class_mode='binary')

import os
from os import listdir
from numpy import asarray
from numpy import save
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
folder = '/content/drive/My Drive/Dataset1/training_set/'
photos, labels = list(), list()
for r, d, f in os.walk(folder):
    for file in f:
        if ".png" in file:
          if(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/training_set/genuine/{}'.format(file)):
            output=1
          elif(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/training_set/forged/{}'.format(file)):
            output=0
        labels.append(output)
labels_train=np.array(labels)
print(os.path.join(r, file))
print(labels_train.shape)
labels_train=np.expand_dims(labels, axis=1)
print(labels_train)
print(labels_train.shape)

import os
from os import listdir
from numpy import asarray
from numpy import save
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
folder = '/content/drive/My Drive/Dataset1/testing_set/'
photos, labels = list(), list()
for r, d, f in os.walk(folder):
    for file in f:
        if ".png" in file:
          if(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/testing_set/genuine/{}'.format(file)):
            output=1
          elif(os.path.join(r, file)=='/content/drive/My Drive/Dataset1/testing_set/forged/{}'.format(file)):
            output=0
        labels.append(output)
labels_test=np.array(labels)
print(os.path.join(r, file))
print(labels_test.shape)
labels_test=np.expand_dims(labels_test, axis=1)
print(labels_test)
print(labels_test.shape)

model_weight_file="/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/model_vgg19_weights.h5"
callbacks = [ModelCheckpoint(model_weights_file, monitor='val_acc', save_best_only=True)]

history = model.fit_generator( train_generator, callbacks = callbacks, nb_epoch=nb_epochs, validation_data=validation_generator)

print('Training Completed!')

# save model and architecture to single file
model.save("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/model_vgg19.h5")
model.summary()

print("Saved model to disk")

# Loading saved model from Drive.
from keras.models import load_model
model = load_model("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/model_vgg19.h5")
print("Model is Loaded")

from keras.models import load_model
layer_name= 'classification_layer'
intermediate_layer_model = Model(inputs=model.input,
                                 outputs=model.get_layer(layer_name).output)

# Compilation of intermediate model
intermediate_layer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print("Model is Complied")

# Saving intermediate model
intermediate_layer_model.save("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/intermediate_model_vgg19.h5")
intermediate_layer_model.summary()

print("Saved Intermediate model to disk")

# Loading Intermediate Model
from keras.models import load_model

model = load_model("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/intermediate_model_vgg19.h5")
print("Intermediate model is loaded")

# Training Label feature identification(y_train)
 import numpy as np
 batch_size=32
 sample_count=2112
 features = np.zeros(shape=(2112, 64))  # Must be equal to the output of the convolutional base
 labels = np.zeros(shape=(2112))
 i = 0
 for inputs_batch, labels_batch in train_generator:
   features_batch = model.predict(inputs_batch)
   features[i * batch_size: (i + 1) * batch_size] = features_batch
   labels[i * batch_size: (i + 1) * batch_size] = labels_batch
   i += 1
   if i*batch_size  >= sample_count:
     break
 print(labels.shape)

#identification of training Labels
features_train=features
print(features_train.shape)
labels_train=np.expand_dims(labels, axis=1)
print(labels_train.shape)
print(labels_train)#identification of training Labels
features_train=features
print(features_train.shape)
print(features_train)

#identification of training Labels
features_train=features
print(features_train.shape)
labels_train=np.expand_dims(labels, axis=1)
print(labels_train.shape)
print(labels_train)

# identification of test labels
 import numpy as np
 batch_size=32
 sample_count=544
 features_test = np.zeros(shape=(544, 64))  # Must be equal to the output of the convolutional base
 labels_test = np.zeros(shape=(544))
 i = 0
 for inputs_batch, labels_batch in validation_generator:
   features_batch = model.predict(inputs_batch)
   features_test[i * batch_size: (i + 1) * batch_size] = features_batch
   labels_test[i * batch_size: (i + 1) * batch_size] = labels_batch
   i += 1
   if i*batch_size  >= sample_count:
     break
 print(labels_test.shape)
 print(features_test.shape)
 print(labels_test)

# #identification of testing Labels
print(features_test.shape)
print(features_test)
labels_test=np.expand_dims(labels_test, axis=1)
print(labels_test.shape)

# SVM
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting SVM to the Training set
from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
classifier.fit(X_train,labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

# Kernel SVM
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.svm import SVC
classifier = SVC(kernel = 'rbf', random_state = 0)
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

# Random Forest
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

# Decision Tree
# Feature Scaling

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

# Naive Bayes
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.neighbors import KNeighborsClassifier
classifier =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(features_train)
X_test = sc.transform(features_test)

# Fitting KernelSVM to the Training set
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, labels_train.ravel())

# Predicting the Test set results
y_pred = classifier.predict(X_test)

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(labels_test, y_pred)
print(cm)
from sklearn.metrics import accuracy_score
print(accuracy_score(labels_test, y_pred))

from google.colab import drive
drive.mount('/content/drive')

from keras.models import load_model

model = load_model("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/model_vgg19.h5")
# Evaluate the model on the test data using `evaluate`
print('\n# Evaluate on test data')
results = model.evaluate(validation_generator)
print('test loss, test acc:', results)

!pip install flask-ngrok

# Mounting Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %mkdir templates -p

# Commented out IPython magic to ensure Python compatibility.
# %%writefile templates/base.html
# <!DOCTYPE html>
# 
# <html lang="en">
# 
# <head>
#     <meta charset="UTF-8">
#     <meta name="viewport" content="width=device-width, initial-scale=1.0">
#     <meta http-equiv="X-UA-Compatible" content="ie=edge">
#     <title>Deep Learning Model Deployment</title>
#     <link href="https://cdn.bootcss.com/bootstrap/4.0.0/css/bootstrap.min.css" rel="stylesheet">
#     <script src="https://cdn.bootcss.com/popper.js/1.12.9/umd/popper.min.js"></script>
#     <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>
#     <script src="https://cdn.bootcss.com/bootstrap/4.0.0/js/bootstrap.min.js"></script>
#     <link href="{{ url_for('static', filename='css/main.css') }}" rel="stylesheet">      
# </head>
# 
# <body>
#     <nav class="navbar navbar-dark bg-dark">
#         <div class="container">
#             <a class="navbar-brand" href="#">AI Demo</a>
#             <button class="btn btn-outline-secondary my-2 my-sm-0" type="submit">Help</button>
#         </div>
#     </nav>
#     <div class="container">
#         <div id="content" style="margin-top:2em">{% block content %}{% endblock %}</div>
#     </div>
# </body>
# 
# <footer>
#     <script src="{{ url_for('static', filename='js/main.js') }}" type="text/javascript"></script>    
# </footer>
# 
# </html>

# Commented out IPython magic to ensure Python compatibility.
# %%writefile templates/index.html
# {% extends "base.html" %} {% block content %}
# 
# <div class="" style="background-color:blue;" >
# <div class="clearfix">
#            
# <div class="col-md-12">
# <center><p style="font-size:40px;color:white;margin-top:10px;">Poornima Institute of Engineering & Technology</p></center> 
# <center><p style="font-size:30px;color:white;margin-top:10px;">Department of Computer Engineering</p></center> 
# <center><p style="font-size:25px;color:white;margin-top:10px;">Deep Learning Model Deployment</p></center> 
# </div>
# </div>
# </div>
# 
# 
# <div>
#     <form id="upload-file" method="post" enctype="multipart/form-data">
#        <center> <input type="file" name="file" id="imageUpload" accept=".png, .jpg, .jpeg"></center>
#     </form>
# 
#     <div class="image-section" style="display:none;">
#         <div class="img-preview">
#             <div id="imagePreview">
#             </div>
#         </div>
#         <div>
#            <center> <button type="button" class="btn btn-primary btn-lg " id="btn-predict">Predict Signature</button></center>
#         </div>
#     </div>
# 
#     <div class="loader" style="display:none;"></div>
# 
#     <h3 id="result">
#         <span> </span>
#     </h3>
# 
# </div>
# 
# {% endblock %}

# Commented out IPython magic to ensure Python compatibility.
# %mkdir static/css -p

# Commented out IPython magic to ensure Python compatibility.
# %%writefile static/css/main.css
# .img-preview {
#     width: 500px;
#     height: 500px;
#     position: relative;
#     border: 5px solid #F8F8F8;
#     box-shadow: 0px 2px 4px 0px rgba(0, 0, 0, 0.1);
#     margin-top: 1em;
#     margin-bottom: 1em; 
#     align-items: center 
#     display: block;
#     margin-left: auto;
#     margin-right: auto;  
# }
# 
# .img-preview>div {
#     width: 100%;
#     height: 100%;
#     background-size: 256px 256px;
#     background-repeat: no-repeat;
#     background-position: center;
#     align-items: center
#     display: block;
#    margin-left: auto;
#    margin-right: auto;
# }
# 
# input[type="file"] {
#     display: none;
#     display: block;
#   margin-left: auto;
#   margin-right: auto;
# }
# 
# .upload-label{
#     display: inline-block;
#     padding: 20px 30px;
#     background: #39D2B4;
#     color: #fff;
#     font-size: 1em;
#     transition: all .4s;
#     cursor: pointer;
#     align-items: center
#     display: block;
#     margin-left: auto;
#     margin-right: auto;
# }
# 
# .upload-label:hover{
#     background: #34495E;
#     color: #39D2B4;
#     align-items: center
# 
# }
# 
# .loader {
#     border: 8px solid #f3f3f3; /* Light grey */
#     border-top: 8px solid #3498db; /* Blue */
#     border-radius: 50%;
#     width: 50px;
#     height: 50px;
#     display: block;
#     margin-left: auto;
#     margin-right: auto;
#     animation: spin 1s linear infinite;
# }
# 
# @keyframes spin {
#     0% { transform: rotate(0deg); }
#     100% { transform: rotate(360deg); }
# }

# Commented out IPython magic to ensure Python compatibility.
# %mkdir static/js -p

# Commented out IPython magic to ensure Python compatibility.
# %mkdir uploads -p

# Commented out IPython magic to ensure Python compatibility.
# %%writefile static/js/main.js
# $(document).ready(function () {
#     // Init
#     $('.image-section').hide();
#     $('.loader').hide();
#     $('#result').hide();
# 
#     // Upload Preview
#     function readURL(input) {
#         if (input.files && input.files[0]) {
#             var reader = new FileReader();
#             reader.onload = function (e) {
#                 $('#imagePreview').css('background-image', 'url(' + e.target.result + ')');
#                 $('#imagePreview').hide();
#                 $('#imagePreview').fadeIn(650);
#             }
#             reader.readAsDataURL(input.files[0]);
#         }
#     }
#     $("#imageUpload").change(function () {
#         $('.image-section').show();
#         $('#btn-predict').show();
#         $('#result').text('');
#         $('#result').hide();
#         readURL(this);
#     });
# 
#     // Predict
#     $('#btn-predict').click(function () {
#         var form_data = new FormData($('#upload-file')[0]);
# 
#         // Show loading animation
#         $(this).hide();
#         $('.loader').show();
# 
#         // Make prediction by calling api /predict
#         $.ajax({
#             type: 'POST',
#             url: '/predict',
#             data: form_data,
#             contentType: false,
#             cache: false,
#             processData: false,
#             async: true,
#             success: function (data) {
#                 // Get and display the result
#                 $('.loader').hide();
#                 $('#result').fadeIn(600);
#                 $('#result').text('                                                             Model Predicted Signature as  :  ' + data);
#                 console.log('Success!');
#             },
#         });
#     });
# 
# });
#

import numpy as np
from flask import Flask, request, jsonify, render_template
from flask_ngrok import run_with_ngrok
import pandas as pd
from __future__ import division, print_function
# coding=utf-8
import sys
import os
import glob
import re
import numpy as np

# Keras
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
from keras.models import load_model
from keras.preprocessing import image

# Flask utils
from flask import Flask, redirect, url_for, request, render_template
from werkzeug.utils import secure_filename


# Define a flask app
app = Flask(__name__)
run_with_ngrok(app)
from keras.models import load_model
model = load_model("/content/drive/My Drive/Colab Notebooks/Signature verification Vgg19 Model/final/model_vgg19.h5")
def model_predict(file_path, model):
    img = image.load_img(file_path, target_size=(128, 128))

    # Preprocessing the image
    x = image.img_to_array(img)
    # x = np.true_divide(x, 255)
    x = np.expand_dims(x, axis=0)

    # Be careful how your trained model deals with the input
    # otherwise, it won't make correct prediction!
    x = preprocess_input(x, mode='caffe')
    preds = model.predict(x)
    return preds


@app.route('/', methods=['GET'])
def index():
    # Main page
    return render_template('index.html')


@app.route('/predict', methods=['GET', 'POST'])
def upload():
    if request.method == 'POST':
        # Get the file from post request
        f = request.files['file']
        f.save('uploads/' + secure_filename(f.filename))
        # Save the file to ./uploads
        
        file_path = os.path.join('/content','uploads', secure_filename(f.filename))
        print(file_path)
        

        # Make prediction
        preds = model_predict(file_path, model)

        # Process your result for human
        # pred_class = preds.argmax(axis=-1)            # Simple argmax
        if(preds> 0.5):
            result= 'Genuine'
        elif(preds< 0.5):
            result='Forged'
        return result
    return None



app.run()